{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T18:09:51.629488Z",
     "start_time": "2019-10-04T18:09:50.844137Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import sys, os\n",
    "\n",
    "# webdriver imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "import webscraping as ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T18:31:45.967853Z",
     "start_time": "2019-10-04T18:09:52.424191Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped so far:\n",
      "Fresh Air | The Moth | TED Talks Daily | Snap Judgment Presents: Spooked | Myths and Legends | Nice Try! | 99% Invisible | Snap Judgment | The Beauty Closet | LeVar Burton Reads | Scary Stories Told in the Dark: A Horror Anthology Series | The Cut on Tuesdays | The Magnus Archives | IN LOVE... with Michael Rosenbaum & Chris Sullivan | The Book Review | Something Scary | Tales | Young House Love Has A Podcast | Cum Town | RISK! | Gals on the Go | The New Yorker: Fiction | Bon Appétit Foodcast | What Should I Read Next? | Inside Trader Joe's | Forever35 | Lauren Conrad: Asking for a Friend | Point of Origin | Merriam-Webster's Word of the Day | Binge Mode: Harry Potter | Chilling Tales for Dark Nights: A Horror Anthology and Scary Stories Series Podcast | Race Chaser with Alaska & Willam | Creative Processing with Joseph Gordon-Levitt | Magic Lessons with Elizabeth Gilbert | Dancing with the Stars Official Podcast | OTR Detective – The Great Detectives of Old Time Radio | The Splendid Table | Weeknight Kitchen with Melissa Clark | Here & Now | The Sporkful | 4 Things with Amy Brown | The New Yorker: The Writer's Voice - New Fiction from The New Yorker | The Allusionist | Marvel's Wolverine | Christopher Kimball’s Milk Street Radio | Gastropod | Wireframe | How To Fail With Elizabeth Day\n",
      "scraping:  The Dave Ramsey Show\n",
      "1827\n",
      "successfully scraped  The Dave Ramsey Show\n",
      "scraping:  How I Built This with Guy Raz\n",
      "176\n",
      "successfully scraped  How I Built This with Guy Raz\n",
      "scraping:  RISE podcast\n",
      "117\n",
      "successfully scraped  RISE podcast\n",
      "scraping:  Planet Money\n",
      "325\n",
      "successfully scraped  Planet Money\n",
      "scraping:  Scam Goddess\n",
      "2\n",
      "successfully scraped  Scam Goddess\n",
      "scraping:  The GaryVee Audio Experience\n",
      "1301\n",
      "successfully scraped  The GaryVee Audio Experience\n",
      "scraping:  The Indicator from Planet Money\n",
      "300\n",
      "successfully scraped  The Indicator from Planet Money\n",
      "scraping:  Jocko Podcast\n",
      "205\n",
      "successfully scraped  Jocko Podcast\n",
      "scraping:  Business Wars\n",
      "168\n",
      "successfully scraped  Business Wars\n",
      "scraping:  The Journal.\n",
      "48\n",
      "successfully scraped  The Journal.\n",
      "scraping:  The Tim Ferriss Show\n",
      "393\n",
      "successfully scraped  The Tim Ferriss Show\n",
      "scraping:  BiggerPockets Real Estate Podcast\n",
      "350\n",
      "successfully scraped  BiggerPockets Real Estate Podcast\n",
      "scraping:  Business Casual\n",
      "3\n",
      "successfully scraped  Business Casual\n",
      "scraping:  RISE Together Podcast\n",
      "66\n",
      "successfully scraped  RISE Together Podcast\n",
      "scraping:  She Makes Money Moves\n",
      "4\n",
      "successfully scraped  She Makes Money Moves\n",
      "scraping:  Hello Monday with Jessi Hempel\n",
      "17\n",
      "successfully scraped  Hello Monday with Jessi Hempel\n",
      "scraping:  WSJ What’s News\n",
      "593\n",
      "successfully scraped  WSJ What’s News\n",
      "scraping:  Marketplace\n",
      "788\n",
      "successfully scraped  Marketplace\n",
      "scraping:  ED MYLETT SHOW\n",
      "\n",
      "successfully scraped  ED MYLETT SHOW\n",
      "scraping:  The Goal Digger Podcast\n",
      "315\n",
      "successfully scraped  The Goal Digger Podcast\n",
      "scraping:  Against the Rules with Michael Lewis\n",
      "10\n",
      "successfully scraped  Against the Rules with Michael Lewis\n",
      "scraping:  HBR IdeaCast\n",
      "708\n",
      "successfully scraped  HBR IdeaCast\n",
      "scraping:  The Chris Hogan Show\n",
      "158\n",
      "successfully scraped  The Chris Hogan Show\n",
      "scraping:  The MFCEO Project\n",
      "323\n",
      "successfully scraped  The MFCEO Project\n",
      "scraping:  ChooseFI\n",
      "284\n",
      "successfully scraped  ChooseFI\n",
      "scraping:  The EntreLeadership Podcast\n",
      "269\n",
      "successfully scraped  The EntreLeadership Podcast\n",
      "scraping:  The Ken Coleman Show\n",
      "559\n",
      "successfully scraped  The Ken Coleman Show\n",
      "scraping:  The Clark Howard Podcast\n",
      "\n",
      "successfully scraped  The Clark Howard Podcast\n",
      "scraping:  WSJ Your Money Briefing\n",
      "332\n",
      "successfully scraped  WSJ Your Money Briefing\n",
      "scraping:  TED Talks Business\n",
      "165\n",
      "successfully scraped  TED Talks Business\n",
      "scraping:  Mad Money w/ Jim Cramer\n",
      "468\n",
      "successfully scraped  Mad Money w/ Jim Cramer\n",
      "scraping:  Christy Wright's Business Boutique\n",
      "88\n",
      "successfully scraped  Christy Wright's Business Boutique\n",
      "scraping:  Rich Dad Radio Show: In-Your-Face Advice on Investing, Personal Finance, & Starting a Business\n",
      "215\n",
      "successfully scraped  Rich Dad Radio Show: In-Your-Face Advice on Investing, Personal Finance, & Starting a Business\n",
      "scraping:  Side Hustle School\n",
      "1047\n",
      "successfully scraped  Side Hustle School\n",
      "scraping:  The Cardone Zone\n",
      "\n",
      "successfully scraped  The Cardone Zone\n",
      "scraping:  We Study Billionaires - The Investor’s Podcast Network\n",
      "266\n",
      "successfully scraped  We Study Billionaires - The Investor’s Podcast Network\n",
      "scraping:  The Smart Passive Income Online Business and Blogging Podcast\n",
      "434\n",
      "successfully scraped  The Smart Passive Income Online Business and Blogging Podcast\n",
      "scraping:  Money Girl's Quick and Dirty Tips for a Richer Life\n",
      "150\n",
      "successfully scraped  Money Girl's Quick and Dirty Tips for a Richer Life\n",
      "scraping:  Talking Green\n",
      "7\n",
      "successfully scraped  Talking Green\n",
      "scraping:  WorkLife with Adam Grant\n",
      "21\n",
      "successfully scraped  WorkLife with Adam Grant\n",
      "scraping:  Masters in Business\n",
      "\n",
      "successfully scraped  Masters in Business\n",
      "scraping:  That Made All the Difference\n",
      "5\n",
      "successfully scraped  That Made All the Difference\n",
      "scraping:  Afford Anything\n",
      "218\n",
      "successfully scraped  Afford Anything\n",
      "scraping:  Online Marketing Made Easy with Amy Porterfield\n",
      "failed scrape for  Online Marketing Made Easy with Amy Porterfield\n",
      "scraping:  Online Marketing Made Easy with Amy Porterfield\n",
      "failed scrape for  Online Marketing Made Easy with Amy Porterfield\n",
      "scraping:  Online Marketing Made Easy with Amy Porterfield\n",
      "failed scrape for  Online Marketing Made Easy with Amy Porterfield\n",
      "scraping:  Online Marketing Made Easy with Amy Porterfield\n",
      "failed scrape for  Online Marketing Made Easy with Amy Porterfield\n",
      "scraping:  Online Marketing Made Easy with Amy Porterfield\n",
      "failed scrape for  Online Marketing Made Easy with Amy Porterfield\n",
      "scraping:  Listen Money Matters - Free your inner financial badass. All the stuff you should know about personal finance.\n",
      "482\n",
      "successfully scraped  Listen Money Matters - Free your inner financial badass. All the stuff you should know about personal finance.\n",
      "scraping:  How to Money\n",
      "129\n",
      "successfully scraped  How to Money\n",
      "scraping:  Masters of Scale with Reid Hoffman\n",
      "65\n",
      "successfully scraped  Masters of Scale with Reid Hoffman\n",
      "scraping:  Earn Your Leisure\n",
      "40\n",
      "successfully scraped  Earn Your Leisure\n",
      "scraping:  Second Life\n",
      "\n",
      "successfully scraped  Second Life\n",
      "scraping:  Coaching for Leaders\n",
      "\n",
      "successfully scraped  Coaching for Leaders\n",
      "scraping:  WSJ Secrets of Wealthy Women\n",
      "\n",
      "successfully scraped  WSJ Secrets of Wealthy Women\n",
      "scraping:  BiggerPockets Money Podcast\n",
      "\n",
      "successfully scraped  BiggerPockets Money Podcast\n",
      "scraping:  Building a StoryBrand with Donald Miller\n",
      "\n",
      "successfully scraped  Building a StoryBrand with Donald Miller\n",
      "scraping:  Andy Stanley Leadership Podcast\n",
      "80\n",
      "successfully scraped  Andy Stanley Leadership Podcast\n",
      "scraping:  Spectacular Failures\n",
      "11\n",
      "successfully scraped  Spectacular Failures\n",
      "scraping:  Women at Work\n",
      "32\n",
      "successfully scraped  Women at Work\n",
      "scraping:  Skimm'd from The Couch\n",
      "\n",
      "successfully scraped  Skimm'd from The Couch\n",
      "scraping:  The Knowledge Project with Shane Parrish\n",
      "67\n",
      "successfully scraped  The Knowledge Project with Shane Parrish\n",
      "scraping:  Suze Orman's Women and Money\n",
      "91\n",
      "successfully scraped  Suze Orman's Women and Money\n",
      "scraping:  WSJ Minute Briefing\n",
      "858\n",
      "successfully scraped  WSJ Minute Briefing\n",
      "scraping:  Behind The Baller Podcast with Ben Baller\n",
      "18\n",
      "successfully scraped  Behind The Baller Podcast with Ben Baller\n",
      "scraping:  Don't Keep Your Day Job\n",
      "203\n",
      "successfully scraped  Don't Keep Your Day Job\n",
      "scraping:  Girlboss Radio with Sophia Amoruso\n",
      "\n",
      "successfully scraped  Girlboss Radio with Sophia Amoruso\n",
      "scraping:  The BossBabe Podcast\n",
      "41\n",
      "successfully scraped  The BossBabe Podcast\n",
      "scraping:  Motley Fool Money\n",
      "545\n",
      "successfully scraped  Motley Fool Money\n",
      "scraping:  The Peter Schiff Show Podcast\n",
      "361\n",
      "successfully scraped  The Peter Schiff Show Podcast\n",
      "scraping:  Entrepreneurs on Fire\n",
      "2297\n",
      "successfully scraped  Entrepreneurs on Fire\n",
      "scraping:  So Money with Farnoosh Torabi\n",
      "966\n",
      "successfully scraped  So Money with Farnoosh Torabi\n",
      "scraping:  The Influencer Podcast\n",
      "178\n",
      "successfully scraped  The Influencer Podcast\n",
      "scraping:  Focus on This\n",
      "6\n",
      "successfully scraped  Focus on This\n",
      "scraping:  Order of Man: Protect | Provide | Preside\n",
      "489\n",
      "successfully scraped  Order of Man: Protect | Provide | Preside\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping:  Make Me Smart with Kai and Molly\n",
      "\n",
      "successfully scraped  Make Me Smart with Kai and Molly\n",
      "scraping:  LEAVE YOUR MARK\n",
      "failed scrape for  LEAVE YOUR MARK\n",
      "scraping:  LEAVE YOUR MARK\n",
      "failed scrape for  LEAVE YOUR MARK\n",
      "scraping:  LEAVE YOUR MARK\n",
      "failed scrape for  LEAVE YOUR MARK\n",
      "scraping:  LEAVE YOUR MARK\n",
      "failed scrape for  LEAVE YOUR MARK\n",
      "scraping:  LEAVE YOUR MARK\n",
      "failed scrape for  LEAVE YOUR MARK\n",
      "scraping:  The Pitch\n",
      "88\n",
      "successfully scraped  The Pitch\n",
      "scraping:  Invest Like the Best\n",
      "156\n",
      "successfully scraped  Invest Like the Best\n",
      "scraping:  The Anxious Achiever\n",
      "2\n",
      "successfully scraped  The Anxious Achiever\n",
      "scraping:  Bloomberg Surveillance\n",
      "1602\n",
      "successfully scraped  Bloomberg Surveillance\n",
      "scraping:  Household Name\n",
      "38\n",
      "successfully scraped  Household Name\n",
      "scraping:  StartUp Podcast\n",
      "138\n",
      "successfully scraped  StartUp Podcast\n",
      "scraping:  The Stacking Benjamins Show\n",
      "\n",
      "successfully scraped  The Stacking Benjamins Show\n",
      "scraping:  The Brian Buffini Show\n",
      "\n",
      "successfully scraped  The Brian Buffini Show\n",
      "scraping:  Legal Wars\n",
      "31\n",
      "successfully scraped  Legal Wars\n",
      "scraping:  Radical Personal Finance\n",
      "727\n",
      "successfully scraped  Radical Personal Finance\n",
      "scraping:  The Side Hustle Show\n",
      "328\n",
      "successfully scraped  The Side Hustle Show\n",
      "scraping:  #MOMTRUTHS with Cat & Nat\n",
      "43\n",
      "successfully scraped  #MOMTRUTHS with Cat & Nat\n",
      "scraping:  Social Media Marketing Podcast\n",
      "339\n",
      "successfully scraped  Social Media Marketing Podcast\n",
      "scraping:  Marketplace All-in-One\n",
      "3655\n",
      "successfully scraped  Marketplace All-in-One\n",
      "scraping:  EmpowerHER\n",
      "\n",
      "successfully scraped  EmpowerHER\n",
      "scraping:  BiggerPockets Business Podcast\n",
      "24\n",
      "successfully scraped  BiggerPockets Business Podcast\n",
      "scraping:  Increase Your Impact with Justin Su'a | A Podcast For Leaders\n",
      "\n",
      "successfully scraped  Increase Your Impact with Justin Su'a | A Podcast For Leaders\n",
      "scraping:  The Investing for Beginners Podcast - Your Path to Financial Freedom\n",
      "121\n",
      "successfully scraped  The Investing for Beginners Podcast - Your Path to Financial Freedom\n",
      "scraping:  Flip The Script\n",
      "5\n",
      "successfully scraped  Flip The Script\n",
      "scraping:  HerMoney with Jean Chatzky\n",
      "\n",
      "successfully scraped  HerMoney with Jean Chatzky\n",
      "scraping:  Do It Scared® with Ruth Soukup\n",
      "78\n",
      "successfully scraped  Do It Scared® with Ruth Soukup\n",
      "scraping:  White Coat Investor Podcast\n",
      "128\n",
      "successfully scraped  White Coat Investor Podcast\n",
      "scraping:  Financial Independence Podcast\n",
      "\n",
      "successfully scraped  Financial Independence Podcast\n",
      "scraping:  CNBC's \"Fast Money\"\n",
      "471\n",
      "successfully scraped  CNBC's \"Fast Money\"\n",
      "scraping:  Marketing School - Digital Marketing and Online Marketing Tips\n",
      "1160\n",
      "successfully scraped  Marketing School - Digital Marketing and Online Marketing Tips\n",
      "scraping:  How to Be Awesome at Your Job\n",
      "294\n",
      "successfully scraped  How to Be Awesome at Your Job\n",
      "scraping:  Lead to Win with Michael Hyatt\n",
      "failed scrape for  Lead to Win with Michael Hyatt\n",
      "scraping:  Lead to Win with Michael Hyatt\n",
      "failed scrape for  Lead to Win with Michael Hyatt\n",
      "scraping:  Lead to Win with Michael Hyatt\n",
      "failed scrape for  Lead to Win with Michael Hyatt\n",
      "scraping:  Lead to Win with Michael Hyatt\n",
      "failed scrape for  Lead to Win with Michael Hyatt\n",
      "scraping:  Lead to Win with Michael Hyatt\n",
      "failed scrape for  Lead to Win with Michael Hyatt\n",
      "no more channels to scrape\n"
     ]
    }
   ],
   "source": [
    "with open('../scraped/channel/podcast_chan_dict-corrected-urls-v2.pickle', 'rb') as file:\n",
    "    chan_dict = pickle.load(file)\n",
    "    \n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "ws.scrape_all_pods_in_category(chan_dict, 'Business', driver, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T18:34:12.997787Z",
     "start_time": "2019-10-04T18:34:12.987663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chan_dict['Business'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T18:34:29.226131Z",
     "start_time": "2019-10-04T18:34:29.222426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chan_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:14:30.411720Z",
     "start_time": "2019-10-03T19:14:30.409296Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:15:02.601068Z",
     "start_time": "2019-10-03T19:15:02.592086Z"
    }
   },
   "outputs": [],
   "source": [
    "re.sub('[\\(\\)]','','(123)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:05:01.849483Z",
     "start_time": "2019-10-03T19:05:01.829644Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../scraped/channel/podcast_chan_dict-corrected-urls.pickle', 'rb') as file:\n",
    "    chan_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T18:01:49.398282Z",
     "start_time": "2019-10-03T18:01:49.394766Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_keys = list(chan_dict.keys())\n",
    "print('sample of categories: \\n', ' | '.join(category_keys[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T18:00:58.776130Z",
     "start_time": "2019-10-03T18:00:58.771585Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate total number of podcasts\n",
    "rows = 0\n",
    "\n",
    "for key in category_keys:\n",
    "    rows += len(chan_dict[key].keys())\n",
    "    \n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T18:01:00.882020Z",
     "start_time": "2019-10-03T18:01:00.874657Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confirm that podcasts are uniquely sorted into a single category\n",
    "\n",
    "podcast_list = []\n",
    "\n",
    "for key in category_keys:\n",
    "    for pod_name in chan_dict[key].keys():\n",
    "        podcast_list += [pod_name]\n",
    "    \n",
    "len(podcast_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, looks like podcasts are uniquely sorted into a single category. Now let's form a sample set from a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T18:10:40.285314Z",
     "start_time": "2019-10-03T18:10:40.281236Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_category = 'Arts'\n",
    "test_category_list = list(chan_dict[test_category].keys())\n",
    "print(f'number of podcasts in {test_category}: ', len(test_category_list))\n",
    "print('sample: ', ' | '.join(test_category_list[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T17:25:36.944098Z",
     "start_time": "2019-10-03T17:25:36.940356Z"
    }
   },
   "outputs": [],
   "source": [
    "category = 'Pets & Animals'\n",
    "\n",
    "# category_str = re.sub('[^A-Za-z0-9]+', '', category)\n",
    "\n",
    "export_path = '../scraped/channel/by_category/' + category + '.csv'\n",
    "\n",
    "with open(export_path, 'w') as file:\n",
    "    file.write('first line, second column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T17:02:10.339083Z",
     "start_time": "2019-10-03T17:02:10.336316Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T17:06:39.365988Z",
     "start_time": "2019-10-03T17:03:36.918900Z"
    }
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "def scrape_sample():\n",
    "    for chan in random.sample(swimming_chans, 10):\n",
    "        chan_url = chan_dict['Swimming'][chan]['chan_url']\n",
    "        features = ws.scrape_channel_page(chan_url, driver, hide=True)\n",
    "#         print(features['title'], features['chan_url'])\n",
    "#         print('first release: ', features['first_release'])\n",
    "\n",
    "scrape_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T16:55:57.517716Z",
     "start_time": "2019-10-03T16:55:57.504036Z"
    }
   },
   "outputs": [],
   "source": [
    "size(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T16:56:10.462818Z",
     "start_time": "2019-10-03T16:56:10.457767Z"
    }
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T16:56:42.718981Z",
     "start_time": "2019-10-03T16:56:42.714861Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.getsizeof(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:24:14.551817Z",
     "start_time": "2019-10-03T19:24:14.546902Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../logs/scrape_log.txt', 'a') as log:\n",
    "    log.write('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T18:56:38.857093Z",
     "start_time": "2019-10-03T18:56:38.854540Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T18:56:51.625719Z",
     "start_time": "2019-10-03T18:56:51.621672Z"
    }
   },
   "outputs": [],
   "source": [
    "str(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:31:20.967187Z",
     "start_time": "2019-10-03T19:31:20.949300Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../scraped/channel/podcast_chan_dict-corrected-urls.pickle', 'rb') as file:\n",
    "    url_list = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:32:09.098297Z",
     "start_time": "2019-10-03T19:32:09.095445Z"
    }
   },
   "outputs": [],
   "source": [
    "url_list['Arts']['99% Invisible']['chan_url'] = 'https://castbox.fm/channel/id18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T19:32:35.668129Z",
     "start_time": "2019-10-03T19:32:35.652658Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../scraped/channel/podcast_chan_dict-corrected-urls-v2.pickle', 'wb') as file:\n",
    "    pickle.dump(url_list, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T20:38:18.207933Z",
     "start_time": "2019-10-03T20:38:17.478203Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T20:13:53.008485Z",
     "start_time": "2019-10-03T20:13:52.862664Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../scraped/channel/by_category/Arts.csv', 'r') as file:\n",
    "    scraped = pd.read_csv(file)\n",
    "    \n",
    "    for line in file:\n",
    "        line\n",
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T20:27:51.695598Z",
     "start_time": "2019-10-03T20:27:51.692516Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'dict': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T20:27:53.482812Z",
     "start_time": "2019-10-03T20:27:53.469465Z"
    }
   },
   "outputs": [],
   "source": [
    "str(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T20:43:04.028742Z",
     "start_time": "2019-10-03T20:43:04.016382Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../scraped/channel/already_scraped.csv', 'r') as file:\n",
    "        scraped = pd.read_csv(file, names=['chan_title','chan_url','category'])\n",
    "scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T20:46:03.564220Z",
     "start_time": "2019-10-03T20:46:03.557523Z"
    }
   },
   "outputs": [],
   "source": [
    "len(scraped[scraped.chan_title == 'Fresh Air'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T21:11:53.019674Z",
     "start_time": "2019-10-03T21:11:53.015077Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "file_name = '../scraped/channel/by_category/test_duplicate_removal.txt'\n",
    "\n",
    "lines_seen = set() # holds lines already seen\n",
    "\n",
    "outfile = open('../scraped/channel/by_category/test_duplicate_removal.txt', \"w\")\n",
    "for line in open(file_name, \"r\"):\n",
    "    if line == '\\n':\n",
    "        outfile.write(line)\n",
    "    elif line not in lines_seen: # not a duplicate\n",
    "        outfile.write(line)\n",
    "        lines_seen.add(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T12:48:19.909074Z",
     "start_time": "2019-10-04T12:48:19.900775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# Clean up Arts category (used for testing)\n",
    "\n",
    "outfile = open('../scraped/channel/by_category/Arts_cleaned.txt', \"w\")\n",
    "\n",
    "lines_seen = set()\n",
    "old_line_count = 0\n",
    "new_line_count = 0\n",
    "for line in open('../scraped/channel/by_category/Arts.txt', \"r\"):\n",
    "    old_line_count += 1\n",
    "    if line == '\\n':\n",
    "        outfile.write(line)\n",
    "        new_line_count += 1\n",
    "    elif line not in lines_seen: # not a duplicate\n",
    "        outfile.write(line)\n",
    "        lines_seen.add(line)\n",
    "        new_line_count += 1\n",
    "outfile.close()\n",
    "\n",
    "print(old_line_count)\n",
    "print(new_line_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "358px",
    "left": "594px",
    "right": "20px",
    "top": "115px",
    "width": "510px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
